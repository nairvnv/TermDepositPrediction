# -*- coding: utf-8 -*-
"""Assignment3.ipynb

Automatically generated by Colaboratory.


"""

from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
from sklearn.neural_network import MLPClassifier
import sys
from keras import backend as K
from tensorflow import keras
import matplotlib.pyplot as plt
from random import randint


class NeuralNet:
    def __init__(self, dataFile, header=True):
        self.raw_input = pd.read_csv(dataFile, header=0, sep=";")
        self.train_history = None
        self.test_history = {}
        self.resultDic = {}
        self.X = None
        self.y = None


    def preprocess(self):
        cleanup_nums = {
            "job": {'housemaid': 0, 'services': 1, 'admin.': 2, 'blue-collar': 3, 'technician': 4, 'retired': 5,
                    'management': 6, 'unemployed': 7, 'self-employed': 8, 'unknown': 9, 'entrepreneur': 10,
                    'student': 11},
            "marital": {'married': 11, 'single': 12, 'divorced': 13, 'unknown': 14},
            "education": {'basic.4y': 15, 'high.school': 16, 'basic.6y': 17, 'basic.9y': 18, 'professional.course': 19,
                          'unknown': 20, 'university.degree': 21, 'illiterate': 22},
            "default": {'no': 21, 'unknown': 22, 'yes': 23},
            "housing": {'no': 24, 'unknown': 25, 'yes': 26},
            "loan": {'no': 27, 'yes': 28, 'unknown': 29},
            "contact": {'telephone': 30, 'cellular': 31},
            "month": {'may': 32, 'jun': 33, 'jul': 34, 'aug': 35, 'oct': 36, 'nov': 37, 'dec': 38, 'mar': 39, 'apr': 40,
                      'sep': 41},
            "day_of_week": {'mon': 42, 'tue': 43, 'wed': 44, 'thu': 45, 'fri': 46},
            "poutcome": {"nonexistent": 47, "failure": 48, 'success': 49},
            "y": {"no": 0, "yes": 1}
            }
        self.processed_data = self.raw_input.replace(cleanup_nums)
        ncols = len(self.processed_data.columns)
        nrows = len(self.processed_data.index)
        self.X = self.processed_data.iloc[:, 0:(ncols - 1)]
        self.y = self.processed_data.iloc[:, (ncols - 1)]

        s = StandardScaler()
        self.X = pd.DataFrame(s.fit(self.X).fit_transform(self.X))



    def plotter(self):

        plt.figure(figsize=(20, 20))
        for i, [params, values] in enumerate(self.resultDic.items()):
            plt.figure()
            plt.title(f'Model Accuracy for: Total Epochs {params.split()[0]} | Learning Rate: {params.split()[1]}')
            # plt.title('Model Accuracy for: Total Epochs ',params.split()[0], '| Learning Rate: ', params.split()[1])
            plt.ylabel('Accuracy')
            plt.xlabel('Epoch')
            for act, accuracy in values['accuracy'].items():
                # print(params)
                plt.plot(accuracy)
                plt.legend(['sigmoid', 'tanh', 'relu'], loc='center right', borderpad=1.5)

        for i, [params, values] in enumerate(self.resultDic.items()):
            plt.figure()
            plt.title(f'Model Loss for: Total Epochs {params.split()[0]} | Learning Rate: {params.split()[1]}')
            plt.ylabel('Loss')
            plt.xlabel('Epoch')
            plt.legend(['sigmoid', 'tanh', 'relu'], loc='center right', borderpad=1.5)
            for act, loss in values['loss'].items():
                # print(params)
                plt.plot(loss)
                plt.legend(['sigmoid', 'tanh', 'relu'], loc='center right', borderpad=1.5)

        plt.subplots_adjust(left=0.1,
                            bottom=0.1,
                            right=0.9,
                            top=1.5,
                            hspace=0.4)
        plt.show()

    def saveData(self, acc, loss, params):
        self.resultDic[str(params[0]) + ' ' + str(params[1])] = {'accuracy': acc, 'loss': loss}
        # print('result dic', self.resultDic)

    def train_evaluate(self):

        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y, random_state=42, test_size=0.2)

        # Below are the hyperparameters that you need to use for model
        # evaluation
        activations = ['sigmoid', 'tanh', 'relu']
        learning_rate = [0.1, ]
        max_iterations = [1]  # also known as epochs
        num_hidden_layers = [2, 3]

        for iterations in max_iterations:
            epoch = iterations
            for lr in learning_rate:
                accuracy = {}
                loss = {}
                for act in activations:
                    model = Sequential()
                    model.add(Dense(2, kernel_initializer='uniform', activation=act))
                    # model.add(Dense(6, kernel_initializer= 'uniform' , activation= act ))
                    model.add(Dense(3, kernel_initializer='uniform', activation=act))

                    opt = keras.optimizers.Adam(learning_rate=lr)
                    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])

                    self.train_history = model.fit(X_train, y_train, validation_split=0.2, epochs=epoch, verbose=0)
                    print('\n(Training Highlight) For total Epochs', epoch, '| Learning Rate:', lr, '| Activation:',
                          act,
                          '\ntesting accuracy obtained:', self.train_history.history['accuracy'][-1],
                          '\ntesting loss obtained:', self.train_history.history['loss'], '\n\n')

                    test_history = model.evaluate(X_test, y_test, return_dict=True, verbose=0)
                    print('\nFor total Epochs', epoch, '| Learning Rate:', lr, '| Activation:', act,
                          '\ntesting accuracy obtained:', test_history['accuracy'],
                          '\ntesting loss obtained:', test_history['loss'], '\n\n')

                    accuracy[act] = self.train_history.history['accuracy']
                    loss[act] = self.train_history.history['loss']
                self.saveData(accuracy, loss, [epoch, lr])

        self.plotter()

        # Create the neural network and be sure to keep track of the performance
        #   metrics

        # Plot the model history for each model in a single plot
        # model history is a plot of accuracy vs number of epochs
        # you may want to create a large sized plot to show multiple lines
        # in a same figure.

        return 0


if __name__ == "__main__":
    neural_network = NeuralNet(
        "https://drive.google.com/uc?id=1tZ9JVouWnswHTezvGA2pSGKKjQ_ilfJN")  # put in path to your file
    neural_network.preprocess()
    neural_network.train_evaluate()